import streamlit as st
import pandas as pd
import os
import joblib
from preprocessing import preprocess_data
from feature_engineering import add_features, segment_customers,calculate_risk_metrics
from modeling import forecast_payments, train_model,format_classification_report
from visualization import plot_customer_segments, plot_payment_forecast, generate_summary_report,generate_risk_summary,plot_risk_heatmap

BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# ==================== Streamlit App ====================
# C·∫•u h√¨nh giao di·ªán
st.set_page_config(page_title="Qu·∫£n l√Ω r·ªßi ro t√≠n d·ª•ng", layout="wide")
DEFAULT_DATA_PATH = os.path.join(BASE_DIR, 'UCI_Credit_Card.csv')
# Ti√™u ƒë·ªÅ ch√≠nh
st.title("Qu·∫£n l√Ω r·ªßi ro t√≠n d·ª•ng")
results = []

# ƒê∆∞·ªùng d·∫´n ƒë·∫øn file ƒë√£ x·ª≠ l√Ω
PROCESSED_DATA_PATH = os.path.join(BASE_DIR,"processed_credit_data.csv")
# Ki·ªÉm tra n·∫øu file ƒë√£ t·ªìn t·∫°i
if os.path.exists(PROCESSED_DATA_PATH):
    processed_data = pd.read_csv(PROCESSED_DATA_PATH)
else:
    st.error("File d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω kh√¥ng t·ªìn t·∫°i. H√£y ch·∫°y script x·ª≠ l√Ω d·ªØ li·ªáu tr∆∞·ªõc.")

# ƒê·ªçc d·ªØ li·ªáu
def load_default_data():
    data = pd.read_csv(DEFAULT_DATA_PATH)
    processed_data = preprocess_data(data)
    processed_data = add_features(processed_data)
    processed_data = segment_customers(processed_data)
    processed_data = calculate_risk_metrics(processed_data)
    return processed_data
processed_data = load_default_data()
st.sidebar.header("T·∫£i l√™n d·ªØ li·ªáu kh√°ch h√†ng m·ªõi")
uploaded_file = st.sidebar.file_uploader("Ch·ªçn file kh√°ch h√†ng m·ªõi (CSV)", type=["csv"])

# Thay th·∫ø ƒëo·∫°n n√†y b·∫±ng logic m·ªõi d√πng m√¥ h√¨nh
# T·∫£i m√¥ h√¨nh ƒë√£ l∆∞u
model_file = "risk_management\modelfile\multioutput_model.pkl"
model = joblib.load(model_file)

# Giao di·ªán t·∫£i d·ªØ li·ªáu kh√°ch h√†ng m·ªõi
if uploaded_file:
    st.sidebar.success("D·ªØ li·ªáu kh√°ch h√†ng m·ªõi ƒë√£ ƒë∆∞·ª£c t·∫£i l√™n!")
    # ƒê·ªçc file kh√°ch h√†ng m·ªõi
    new_customer_data = pd.read_csv(uploaded_file)
    st.write("### D·ªØ li·ªáu kh√°ch h√†ng m·ªõi:")
    st.dataframe(new_customer_data)

    # T√≠nh c√°c ch·ªâ s·ªë r·ªßi ro
    features = ["LIMIT_BAL", "Credit_Utilization", "Repayment_Trend"]
    new_customer_data = preprocess_data(new_customer_data)
    new_customer_data = add_features(new_customer_data)
    new_customer_data = segment_customers(new_customer_data)
    #new_customer_data = calculate_risk_metrics(new_customer_data)
    input_data = new_customer_data[features]

    # D·ª± ƒëo√°n c√°c ch·ªâ s·ªë
    predictions = model.predict(input_data)
    new_customer_data[["PD", "LGD", "EAD", "EL"]] = predictions

    # Hi·ªÉn th·ªã k·∫øt qu·∫£
    st.write("### K·∫øt qu·∫£ d·ª± ƒëo√°n:")
    st.dataframe(new_customer_data[["LIMIT_BAL", "PD", "LGD", "EAD", "EL"]])
else:
    st.info("H√£y t·∫£i l√™n file CSV ch·ª©a d·ªØ li·ªáu kh√°ch h√†ng m·ªõi ƒë·ªÉ ƒë√°nh gi√°.")
if results:
    st.write("### K·∫øt qu·∫£ ƒë√°nh gi√° r·ªßi ro (m·∫∑c ƒë·ªãnh)")
    st.dataframe(pd.DataFrame(results))
    # T√≠nh to√°n c√°c ch·ªâ s·ªë r·ªßi ro t√≠n d·ª•ng
processed_data = calculate_risk_metrics(processed_data)
st.write("### B√°o c√°o r·ªßi ro t√≠n d·ª•ng")
risk_summary = generate_risk_summary(processed_data)
for key, value in risk_summary.items():
    st.write(f"{key}: {value:.2f}")
# Tab ch·ª©c nƒÉng
tab1, tab2, tab3 = st.tabs(["üìä T·ªïng quan", "üìà Ph√¢n t√≠ch & D·ª± b√°o", "ü§ñ Hu·∫•n luy·ªán m√¥ h√¨nh"])
# Tab 1: T·ªïng quan
with tab1:
    st.header("B√°o c√°o t·ªïng h·ª£p")
    st.write("### Danh s√°ch kh√°ch h√†ng v·ª° n·ª£")
    generate_summary_report(processed_data)
    
    # Hi·ªÉn th·ªã b·∫£ng d·ªØ li·ªáu m·∫´u
    st.dataframe(processed_data)
# Tab 2: Ph√¢n t√≠ch & D·ª± b√°o
with tab2:
    st.header("Ph√¢n t√≠ch ph√¢n kh√∫c kh√°ch h√†ng")
    st.pyplot(plot_customer_segments(processed_data))
    st.header("D·ª± b√°o d√≤ng ti·ªÅn thanh to√°n")
    processed_data, reg_model = forecast_payments(processed_data)
    st.pyplot(plot_payment_forecast(processed_data))
    from visualization import plot_risk_heatmap
    st.header("T∆∞∆°ng quan gi·ªØa c√°c ch·ªâ s·ªë r·ªßi ro")
    heatmap_fig = plot_risk_heatmap(processed_data)
    st.pyplot(heatmap_fig)
    # Tab 3: Hu·∫•n luy·ªán m√¥ h√¨nh
with tab3:
    st.header("K·∫øt qu·∫£ hu·∫•n luy·ªán m√¥ h√¨nh")
    # Hu·∫•n luy·ªán m√¥ h√¨nh v√† l·∫•y b√°o c√°o
    with st.spinner("ƒêang hu·∫•n luy·ªán m√¥ h√¨nh..."):
        model_with_smote, classification_report_str, auc_roc = train_model(processed_data)
    # ƒê·ªãnh d·∫°ng v√† hi·ªÉn th·ªã b√°o c√°o ph√¢n lo·∫°i
    st.subheader("B√°o c√°o ph√¢n lo·∫°i:")
    report_df = format_classification_report(classification_report_str)
    st.dataframe(report_df)  # Hi·ªÉn th·ªã d∆∞·ªõi d·∫°ng b·∫£ng
    # Hi·ªÉn th·ªã ch·ªâ s·ªë AUC-ROC
    st.subheader("Ch·ªâ s·ªë AUC-ROC:")
    st.metric(label="AUC-ROC", value=f"{auc_roc:.4f}")
    st.success("ƒê√£ hu·∫•n luy·ªán v√† ƒë√°nh gi√° m√¥ h√¨nh v·ªõi k·ªπ thu·∫≠t SMOTE ƒë·ªÉ x·ª≠ l√Ω m·∫•t c√¢n b·∫±ng d·ªØ li·ªáu.")
    st.write("### K·∫øt qu·∫£ ƒë√°nh gi√° r·ªßi ro")
    st.dataframe(pd.DataFrame(results))



